# Model Selection for Logistic Regression

## Overview
This Jupyter notebook explores model selection techniques for logistic regression, focusing on optimizing feature selection to improve model performance. It includes exploratory data analysis, feature engineering, model training with logistic regression, and evaluations using metrics such as AUC-ROC.

## Key Features
- **Data Preprocessing:** Cleaning and preparing data for modeling.
- **Feature Engineering:** Transforming variables to better expose patterns to modeling algorithms.
- **Model Training:** Setting up logistic regression models using `scikit-learn`.
- **Model Evaluation:** Calculating AUC-ROC to evaluate model performance.
- **Feature Selection:** Utilizing Recursive Feature Elimination (RFE) to select the most significant predictors.
- **Model Persistence:** Saving the optimized model using `pickle`.

## Requirements
- Python 3.8+
- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`
- `seaborn`
- `pickle`

## Usage
1. **Load the Notebook:** Open this notebook in a Jupyter environment.
2. **Install Dependencies:** Ensure all required libraries are installed.
3. **Run the Notebook:** Execute the cells sequentially to observe the workflow from data loading to model persistence.

## Contributing
Feel free to fork this project, make improvements, or adapt the workflow for different datasets or logistic regression scenarios. Contributions are always welcome!

## License
This project is open-sourced under the MIT License.

## Contact
For any queries or discussions regarding improvements or collaborations, please contact the project maintainer at [your-email@example.com].

## Acknowledgments
This project utilizes publicly available data and `scikit-learn` for model training and evaluation.
